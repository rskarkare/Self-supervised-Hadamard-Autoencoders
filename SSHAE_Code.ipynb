{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fd3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96239c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu usage\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset \n",
    "data = pd.read_csv('./MMdata.csv')\n",
    "data_original = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 5 copies of each row for using for self-supervision\n",
    "data_original = np.array(data_original)\n",
    "data_original = np.repeat(data_original, repeats=5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.DataFrame(data_original)\n",
    "#data_original = data_original.to_csv('./data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nas and reset index and Quality columns\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed76d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the features \n",
    "data = pd.DataFrame(data)\n",
    "Quality = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data_original.columns\n",
    "#data = data.drop(['Quality'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f29883",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c770495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset using stdscaler/MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data_norm = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = pd.DataFrame(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3814e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data_norm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea14fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.shape, data_norm.min(), data_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data_norm.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quality = Quality.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quality = Quality.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14507746",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457aa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the final transformed dataset with the quality levels\n",
    "data_norm = pd.concat([data_norm,Quality], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a84d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ffc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_norm.to_csv('./data_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf73111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_norm.columns = data_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fd60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into a numpy array and check for any na values\n",
    "data_norm = np.array(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isnan(data_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = data_norm[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97974e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_norm[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the indicator matrix of ones and zeros to mark the missing entries in the data\n",
    "hadamard = np.ones(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask entries in the dataset. Mark entries in either a MAR or NMAR manner depending on the mechanism of missingness present in the dataset.\n",
    "import random\n",
    "def mask_randomly(X):\n",
    "    #hadamard_train = np.ones(X.shape)\n",
    "    block_size = 8\n",
    "    row_rand_list = list(np.random.randint(0, (X.shape[0]-block_size), 100))\n",
    "    col_rand_list = []\n",
    "    for i in row_rand_list:\n",
    "        col_rand = random.randint(0, X.shape[1]-block_size)\n",
    "        col_rand_list.append(col_rand)\n",
    "        for j in range(block_size):\n",
    "            for k in range(block_size):\n",
    "                X[i+j][col_rand+k] = -1 \n",
    "    #hadamard_train = np.where(data == -1, 0, hadamard_train)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val and test sets for original dataset as well as indicator matrix\n",
    "X_train, X_test, y_train, y_test, hadamard_train, hadamard_test = train_test_split(X, y, hadamard,test_size=0.33,shuffle=True)\n",
    "X_train, X_val, y_train, y_val, hadamard_train, hadamard_val = train_test_split(X_train, y_train, hadamard_train, test_size=0.01 ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the originals for metric calcultaion\n",
    "X_train_original = X_train.copy()\n",
    "X_val_original = X_val.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incomplete dataset\n",
    "X_train_inc = mask_randomly(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the different percentage of deletion code - this is another mechanism of missingness \n",
    "def codefordeletion(data, hadamard, frac):\n",
    "    [Rn, Cn] = data.shape\n",
    "    ind = []\n",
    "    for i in range(Rn):\n",
    "        for j in range(Cn):\n",
    "            ind.append(data[i, j])\n",
    "    fraction = frac\n",
    "        # calculate entries to be deleted\n",
    "    rem_num = ((len(ind)) * fraction / 100)  # total number of entries to be removed\n",
    "        # has to be an integer value\n",
    "    rem_num = int(rem_num)\n",
    "        # select random elements from the upper triangle:\n",
    "    indices = np.random.choice(len(ind), rem_num, replace=False)\n",
    "        # make these indices -1\n",
    "    for i in indices:\n",
    "        ind[i] = -1  # now place these values back in the upper triangle:\n",
    "    #print(ind)\n",
    "    p = 0\n",
    "    for i in range(Rn):\n",
    "        for j in range(Cn):\n",
    "            data[i, j] = ind[p]\n",
    "            p += 1\n",
    "    print(data)\n",
    "    print(hadamard)\n",
    "    hadamard = np.where(data == -1, 0, hadamard)\n",
    "    return data, hadamard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00541517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define corresponding hadamard for train, validation and test sets\n",
    "hadamard_train = np.ones(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_inc, hadamard_train = codefordeletion(X_train, hadamard_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, hadamard_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_train = np.where(X_train_inc == -1, 0, hadamard_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadamard_train = pd.DataFrame(hadamard_train)\n",
    "#hadamard_train.to_csv('had_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_inc, hadamard_train  = codefordeletion(X_train, hadamard_train, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_inc = pd.DataFrame(X_train_inc)\n",
    "#X_train_inc.to_csv('./X_train_inc1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inc = np.where(X_train_inc == -1, np.nan, X_train_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadamard_train = pd.DataFrame(hadamard_train)\n",
    "#hadamard_train.to_csv('./hadamard1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb555c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_inc)\n",
    "\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean_train = np.nanmean(X_train_inc, axis=0)\n",
    "\n",
    "print(col_mean_train)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_train_inc))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_train_inc[inds] = np.take(col_mean_train, inds[1])\n",
    "\n",
    "print(X_train_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the validation test\n",
    "#X_val_inc, hadamard_val = codefordeletion(X_val, hadamard_val, 20)\n",
    "#X_val_inc = np.where(X_val_inc == -1, np.nan, X_val_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly for the validation and test sets\n",
    "X_val_inc = mask_randomly(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_val = np.ones(X_val_inc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_val = np.where(X_val_inc == -1, 0, hadamard_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_inc = np.where(X_val_inc == -1, np.nan, X_val_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc97eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all missing entries with mean values\n",
    "print(X_val_inc)\n",
    "\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean_val = np.nanmean(X_val_inc, axis=0)\n",
    "\n",
    "print(col_mean_val)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_val_inc))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_val_inc[inds] = np.take(col_mean_val, inds[1])\n",
    "\n",
    "print(X_val_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = np.repeat(y_train, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aadd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(y_val)\n",
    "y_val = np.repeat(y_val, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19186d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of the train and validation sets\n",
    "X_train_inc = np.array(X_train_inc)\n",
    "X_train_inc = np.repeat(X_train_inc, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the test set\n",
    "#X_test_inc, hadamard_test = codefordeletion(X_test, hadamard_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of the train and validation sets\n",
    "X_val_inc = np.array(X_val_inc)\n",
    "X_val_inc = np.repeat(X_val_inc, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_train = np.array(hadamard_train)\n",
    "hadamard_train = np.repeat(hadamard_train, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_val = np.array(hadamard_val)\n",
    "hadamard_val = np.repeat(hadamard_val, repeats=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a40977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = np.array(X_train_original)\n",
    "X_train_original = np.repeat(X_train_original, repeats=10, axis=0)\n",
    "X_val_original = np.array(X_val_original)\n",
    "X_val_original = np.repeat(X_val_original, repeats=10, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_inc = mask_randomly(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_test = np.ones(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_inc, hadamard_test = codefordeletion(X_test, hadamard_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_test = np.where(X_test_inc == -1, 0, hadamard_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afcb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_inc = np.where(X_test_inc == -1, np.nan, X_test_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd724fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_inc)\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean_test = np.nanmean(X_test_inc, axis=0)\n",
    "\n",
    "print(col_mean_test)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_test_inc))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_test_inc[inds] = np.take(col_mean_test, inds[1])\n",
    "\n",
    "print(X_test_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f16988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now these are the targets for training the network\n",
    "X_train_target = X_train_inc.copy()\n",
    "X_val_target = X_val_inc.copy()\n",
    "X_test_target = X_test_inc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ade81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mean_test = list(col_mean_test)\n",
    "col_mean_train = list(col_mean_train)\n",
    "col_mean_val = list(col_mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define the inputs\n",
    "X_train_inputs = X_train_target.copy()\n",
    "X_val_inputs = X_val_target.copy()\n",
    "X_test_inputs = X_test_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0853b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1845f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the different percentage of deletion code - This is for missing at random as was done until now. \n",
    "def codefordeletion2(data, hadamards,  frac):\n",
    "    [Rn, Cn] = data.shape\n",
    "    ind = []\n",
    "    for i in range(Rn):\n",
    "        for j in range(Cn):\n",
    "            ind.append(data[i, j])\n",
    "    fraction = frac\n",
    "        # calculate entries to be deleted\n",
    "    rem_num = ((len(ind)) * fraction / 100)  # total number of entries to be removed\n",
    "        # has to be an integer value\n",
    "    rem_num = int(rem_num)\n",
    "        # select random elements from the upper triangle:\n",
    "    indices = np.random.choice(len(ind), rem_num, replace=False)\n",
    "        # make these indices -1\n",
    "    # check hadamards of corresponding indices\n",
    "    had = []\n",
    "    for i in range(Rn):\n",
    "        for j in range(Cn):\n",
    "            had.append(hadamards[i, j])\n",
    "    for i in indices:\n",
    "        #if ind[i] not in col_mean:\n",
    "        if had[i] != 0:\n",
    "            ind[i] = -1  # now place these values back in the upper triangle:\n",
    "    #print(ind)\n",
    "    p = 0\n",
    "    for i in range(Rn):\n",
    "        for j in range(Cn):\n",
    "            data[i, j] = ind[p]\n",
    "            p += 1\n",
    "    #print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7321df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_randomly2(X, hadamard):\n",
    "    #hadamard_train = np.ones(X.shape)\n",
    "    block_size = 8\n",
    "    row_rand_list = list(np.random.randint(0, (X.shape[0]-block_size), 30))\n",
    "    col_rand_list = []\n",
    "    for i in row_rand_list:\n",
    "        col_rand = random.randint(0, X.shape[1]-block_size)\n",
    "        col_rand_list.append(col_rand)\n",
    "        for j in range(block_size):\n",
    "            for k in range(block_size):\n",
    "                if hadamard[i+j][col_rand+k] != 0:\n",
    "                    X[i+j][col_rand+k] = -1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inputs = codefordeletion2(X_train_inputs, hadamard_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_inputs = mask_randomly2(X_train_inputs, hadamard_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inputs = np.where(X_train_inputs == -1, np.nan, X_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_inputs)\n",
    "\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean = np.nanmean(X_train_inputs, axis=0)\n",
    "\n",
    "print(col_mean)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_train_inputs))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_train_inputs[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "print(X_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the validation test\n",
    "X_val_inputs = codefordeletion2(X_val_inputs, hadamard_val, 0)\n",
    "#X_val_inputs = mask_randomly2(X_val_inputs, hadamard_val)\n",
    "X_val_inputs = np.where(X_val_inputs == -1, np.nan, X_val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val_inputs)\n",
    "\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean = np.nanmean(X_val_inputs, axis=0)\n",
    "\n",
    "print(col_mean)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_val_inputs))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_val_inputs[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "print(X_val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee733e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train_inputs = pd.DataFrame(X_train_inputs)\n",
    "X_train_target = pd.DataFrame(X_train_target)\n",
    "hadamard_train = pd.DataFrame(hadamard_train)\n",
    "X_train_inputs.to_csv('inputs.csv')\n",
    "X_train_target.to_csv('targets.csv')\n",
    "hadamard_train.to_csv('hadamard.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the test set\n",
    "#X_test_inputs = codefordeletion2(X_test_inputs, hadamard_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_inputs = np.where(X_test_inputs == -1, np.nan, X_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_inputs)\n",
    "'''\n",
    "#Obtain mean of columns as you need, nanmean is convenient.\n",
    "col_mean = np.nanmean(X_test_inputs, axis=0)\n",
    "\n",
    "print(col_mean)\n",
    "\n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(X_test_inputs))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X_test_inputs[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "print(X_test_inputs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset\n",
    "class MMData(Dataset):\n",
    "    def __init__(self, X_input, X_target, X_original, hadamard):\n",
    "        self.X_input = X_input.copy()\n",
    "        self.X_target = X_target.copy()\n",
    "        self.X_original = X_original.copy()\n",
    "        self.hadamard = hadamard.copy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_input)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_input[idx], self.X_target[idx], self.X_original[idx], self.hadamard[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc690c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder architecture\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(97, 45)\n",
    "        self.fc2 = nn.Linear(45, 16)\n",
    "        self.fc3 = nn.Linear(16, 45)\n",
    "        self.fc4 = nn.Linear(45, 97)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc2(h1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h2 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, 97))\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder architecture\n",
    "'''\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(97, 34)\n",
    "        self.fc2 = nn.Linear(34, 8)\n",
    "        self.fc3 = nn.Linear(8, 34)\n",
    "        self.fc4 = nn.Linear(34, 97)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc2(h1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h2 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, 97))\n",
    "        return self.decode(z)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and valid datasets\n",
    "train_ds = MMData(X_train_inputs, X_train_target, X_train_original, hadamard_train)\n",
    "valid_ds = MMData(X_val_inputs, X_val_target, X_val_original, hadamard_val)\n",
    "test_ds = MMData(X_test_inputs, X_test_target, X_test_original, hadamard_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "def loss_function(Y_hat, Y, Omega):\n",
    "    loss = torch.sum(Omega*(Y_hat-Y)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf09c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and optimizer\n",
    "model = AutoEncoder()\n",
    "model.to('cuda:0')\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55caecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and validation loops\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_train = []\n",
    "    orig_train = []\n",
    "    hadamards_train = []\n",
    "    for X_train_inputs, X_train_target, X_train_original, hadamard_train in tqdm(train_dl):\n",
    "        X_train_inputs, X_train_target, X_train_original, hadamard_train = X_train_inputs.cuda(), X_train_target.cuda(), X_train_original.cuda(), hadamard_train.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(X_train_inputs.float())\n",
    "        loss = loss_function(recon, X_train_target, hadamard_train)      \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step() \n",
    "        if epoch == 200:\n",
    "            preds_train.append(recon.cpu().detach().numpy())\n",
    "            orig_train.append(X_train_original.cpu().detach().numpy())\n",
    "            hadamards_train.append(hadamard_train.cpu().detach().numpy())            \n",
    "    train_loss=train_loss/len(train_dl)\n",
    "    train_losses.append(train_loss)\n",
    "    print('Train Loss: %.3f'%(train_loss))\n",
    "    return train_losses, preds_train, orig_train, hadamards_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the validation epochs\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    preds_val = []\n",
    "    orig_val = []\n",
    "    hadamards_val = []\n",
    "    with torch.no_grad():\n",
    "        for X_val_inputs, X_val_target, X_val_original, hadamard_val in tqdm(valid_dl):\n",
    "            X_val_inputs, X_val_target, X_val_original, hadamard_val = X_val_inputs.cuda(), X_val_target.cuda(), X_val_original.cuda(), hadamard_val.cuda()\n",
    "            recon=model(X_val_inputs.float())\n",
    "            loss = loss_function(recon, X_val_target, hadamard_val) \n",
    "            running_loss+=loss.item()\n",
    "            if epoch == 200:\n",
    "                preds_val.append(recon.cpu().detach().numpy())\n",
    "                orig_val.append(X_val_original.cpu().detach().numpy())\n",
    "                hadamards_val.append(hadamard_val.cpu().detach().numpy()) \n",
    "        eval_loss=running_loss/len(valid_dl)\n",
    "        eval_losses.append(eval_loss)\n",
    "    print('Validation Loss: %.3f' %(eval_loss))\n",
    "    return eval_losses, preds_val, orig_val, hadamards_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53192d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the train and val loops\n",
    "epochs=200\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "for epoch in range(1,epochs+1): \n",
    "    train_losses, preds_train, orig_train, hadamards_train = train(epoch)\n",
    "    eval_losses, preds_val, orig_val, hadamards_val = val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the train and validation lossto monitor convergence\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\", fontsize = 15)\n",
    "plt.plot(eval_losses, '-o', label=\"Val_loss\")\n",
    "plt.plot(train_losses, '-o', label=\"Train_loss\")\n",
    "plt.xlabel(\"Iterations\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid(linestyle = '--', linewidth = 0.2)\n",
    "#plt.savefig('./loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    recon_test = []\n",
    "    original_test = []\n",
    "    hadamards_test = []\n",
    "    with torch.no_grad():\n",
    "        for X_test_inputs, X_test_target, X_test_original, hadamard_test in tqdm(test_dl):\n",
    "            X_test_inputs, X_test_target, X_test_original, hadamard_test = X_test_inputs.cuda(), X_test_target.cuda(), X_test_original.cuda(), hadamard_test.cuda()\n",
    "            recon=model(X_test_inputs.float())\n",
    "            loss = loss_function(recon, X_test_target, hadamard_test) \n",
    "            running_loss+=loss.item()\n",
    "            recon_test.append(recon.cpu().detach().numpy())\n",
    "            original_test.append(X_test_original.cpu().detach().numpy())\n",
    "            hadamards_test.append(hadamard_test.cpu().detach().numpy())            \n",
    "        eval_loss=running_loss/len(test_dl)\n",
    "        eval_losses.append(eval_loss)\n",
    "    print('Validation Loss: %.3f' %(eval_loss))\n",
    "    return recon_test, original_test, hadamards_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb18112",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test, original_test, hadamards_test = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad652b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original as well as reconstructed datasets\n",
    "recon_test = np.vstack(recon_test)\n",
    "original_test = np.vstack(original_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16004ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamards_test = np.vstack(hadamards_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamards_test.shape, recon_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91c29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546affad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the observed entries in the reconstructed set\n",
    "recon_test[hadamards_test == 1.0] = original_test[hadamards_test == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test.shape, original_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test = pd.DataFrame(recon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = pd.DataFrame(original_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49563504",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test.columns = data_original.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test.columns = data_original.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f04be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_test = pd.DataFrame(recon_test)\n",
    "recon_test.to_csv('C:\\\\Users\\\\16175\\\\Desktop\\\\recon_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = pd.DataFrame(original_test)\n",
    "original_test.to_csv('C:\\\\Users\\\\16175\\\\Desktop\\\\original_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f835ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics on the unobserved entries of the tesset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(original_test, recon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamards_test = np.array(hadamards_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5adab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation calculate the metric on the unobserved entries of the test set this is relative absolute error. \n",
    "[r,c] = original_test.shape\n",
    "hop = np.zeros((r*c))\n",
    "ori = np.zeros((r*c))\n",
    "meane = []\n",
    "abse = []\n",
    "\n",
    "##################################################################\n",
    "\t#  mean  and absolute hop error calculation----------------\n",
    "print(\"-------------- Calculating error -----------------\")\n",
    "\n",
    "[r, c] = original_test.shape\n",
    "        # vectorize matrices - placeholders\n",
    "hop = []\n",
    "ori = []\n",
    "\n",
    "p = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        if hadamards_test[i, j] == 0:  # considers error on only unobserved entries\n",
    "            hop.append(recon_test[i, j])\n",
    "            ori.append(original_test[i, j])\n",
    "            p = p + 1\n",
    "\n",
    "hop = np.array(hop)\n",
    "ori = np.array(ori)\n",
    "x = np.round(hop - ori)\n",
    "\n",
    "print (\"numerator:\", np.sum(abs(x)))\n",
    "print (\"sum of unobserved entries:\", np.sum(ori))\n",
    "print (\"b: total unobserved entries:\", len(ori))\n",
    "\n",
    "mean_err = (np.sum(abs(x))) / (np.sum(ori))\n",
    "mean_err = mean_err * 100\n",
    "mean_std = np.std(abs(x))\n",
    "\n",
    "abs_err = (np.sum(abs(x))) / (len(ori))  # divided by the number of unobserved entries\n",
    "abs_std = np.std(abs(x))\n",
    "\n",
    "print(mean_err)\n",
    "print(abs_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
